{"paragraphs":[{"text":"%md \n\n### Random Forest Classification in Scala using Spark ML \n\n*Hadi*","user":"anonymous","dateUpdated":"2018-02-22T08:31:34-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Random Forest Classification in Scala using Spark ML</h3>\n<p><em>Hadi</em></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171225-164722_1822736710","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:34-0800","dateFinished":"2018-02-22T08:31:34-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15344"},{"text":"%md\n\n#### Recap:\n<b> Spark ML</b>: Works with DataFrames (vs. Spark Mllib works with RDDs)\n\n<b>DataFrame</b>: This ML API uses DataFrame from Spark SQL as an ML dataset, which can hold a variety of data types. E.g., a DataFrame could have different columns storing text, feature vectors, true labels, and predictions.\n\n<b>Transformer</b>: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions.\n\n<b>Estimator</b>: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.\n\n<b>Pipeline</b>: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.\n\n(from spark.apache.org)","user":"anonymous","dateUpdated":"2018-02-22T08:31:37-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Recap:</h4>\n<p><b> Spark ML</b>: Works with DataFrames (vs. Spark Mllib works with RDDs)</p>\n<p><b>DataFrame</b>: This ML API uses DataFrame from Spark SQL as an ML dataset, which can hold a variety of data types. E.g., a DataFrame could have different columns storing text, feature vectors, true labels, and predictions.</p>\n<p><b>Transformer</b>: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions.</p>\n<p><b>Estimator</b>: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.</p>\n<p><b>Pipeline</b>: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.</p>\n<p>(from spark.apache.org)</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171231-173028_1024443740","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:37-0800","dateFinished":"2018-02-22T08:31:37-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15345"},{"text":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types._\n\nval schemaStruct =\n        StructType(\n            StructField(\"state\", StringType, false) ::\n            StructField(\"gender\", StringType, false) ::\n            StructField(\"income\", DoubleType, false) :: \n            StructField(\"owns_car\", StringType, true) :: Nil)\n\nval dataDF = spark\n            .read\n            .schema(schemaStruct)\n            .option(\"header\", \"true\")\n            .csv(\"/Users/hadi.minooei/Documents/DSbyHadi/car_ownership.csv\")","user":"anonymous","dateUpdated":"2018-02-22T16:55:52-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types._\nschemaStruct: org.apache.spark.sql.types.StructType = StructType(StructField(state,StringType,false), StructField(gender,StringType,false), StructField(income,DoubleType,false), StructField(owns_car,StringType,true))\ndataDF: org.apache.spark.sql.DataFrame = [state: string, gender: string ... 2 more fields]\n"}]},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171225-162607_709880967","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T16:55:53-0800","dateFinished":"2018-02-22T16:55:55-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15346"},{"text":"dataDF.count\ndataDF.columns\ndataDF.printSchema","user":"anonymous","dateUpdated":"2018-02-22T16:55:59-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1478: Long = 13\nres1479: Array[String] = Array(state, gender, income, owns_car)\nroot\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- income: double (nullable = true)\n |-- owns_car: string (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171230-112014_1719391521","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T16:55:59-0800","dateFinished":"2018-02-22T16:56:01-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15347"},{"text":"// We need to predict owns_car --> response\n// Three features to be used: state, gender and income\n// 'income' is a continuous feature \n// 'state' and 'gender' are categorical features","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171225-164405_808048175","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:34-0800","dateFinished":"2018-02-22T08:31:35-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15348"},{"text":"// We need to index the owns_car i.e. true -> 0.0 and false -> 1.0 or vice versa.\n// For this we use StringIndexer.","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171225-164950_1144267600","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:35-0800","dateFinished":"2018-02-22T08:31:36-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15349"},{"text":"import org.apache.spark.ml.feature.{StringIndexer}\n\nval labelIndexer = new StringIndexer()\n        .setInputCol(\"owns_car\")\n        .setOutputCol(\"owns_car_index\")\n        .fit(dataDF)","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.feature.StringIndexer\nlabelIndexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_00cb53d92cb9\n"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-111645_1636461841","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:36-0800","dateFinished":"2018-02-22T08:31:36-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15350"},{"text":"labelIndexer.transform(dataDF).columns\nlabelIndexer.transform(dataDF).take(4)","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1257: Array[String] = Array(id, state, gender, owns_car, income, owns_car_index)\nres1258: Array[org.apache.spark.sql.Row] = Array([1,CA,male,false,40000.0,1.0], [2,CA,female,false,50000.0,1.0], [3,UT,female,true,35000.0,0.0], [4,UT,female,false,20000.0,1.0])\n"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-182705_1615244198","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:36-0800","dateFinished":"2018-02-22T08:31:37-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15351"},{"text":"// 'income' is a continuous feature \n\n// 'state' and 'gender' are categorical features, so need to be indexed.","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171231-184422_1966221586","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:37-0800","dateFinished":"2018-02-22T08:31:38-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15352"},{"text":"%md\n##### No need to do OneHotEncoding","user":"anonymous","dateUpdated":"2018-02-22T08:31:41-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>No need to do OneHotEncoding</h5>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20180208-193038_2116727936","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:41-0800","dateFinished":"2018-02-22T08:31:41-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15353"},{"text":"val genderIndexer = new StringIndexer()\n        .setInputCol(\"gender\")\n        .setOutputCol(\"gender\" + \"_index\")\n        .setHandleInvalid(\"skip\")\n        .fit(dataDF)","user":"anonymous","dateUpdated":"2018-02-22T10:31:52-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"genderIndexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_4c1aea518266\n"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-111727_1248125003","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T10:31:52-0800","dateFinished":"2018-02-22T10:31:53-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15354"},{"text":"val stateIndexer = new StringIndexer()\n        .setInputCol(\"state\")\n        .setOutputCol(\"state\" + \"_index\")\n        .setHandleInvalid(\"skip\")\n        .fit(dataDF)","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"stateIndexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_8a221dce5fbe\n"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-111727_1105500600","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:38-0800","dateFinished":"2018-02-22T08:31:39-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15355"},{"text":"val test1 = stateIndexer.transform(dataDF)\nval test2 = genderIndexer.transform(test1)","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"test1: org.apache.spark.sql.DataFrame = [id: string, state: string ... 4 more fields]\ntest2: org.apache.spark.sql.DataFrame = [id: string, state: string ... 5 more fields]\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-111726_1473112042","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:39-0800","dateFinished":"2018-02-22T08:31:40-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15356"},{"text":"test2.columns\ntest2.take(6)","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1264: Array[String] = Array(id, state, gender, owns_car, income, state_index, gender_index)\nres1265: Array[org.apache.spark.sql.Row] = Array([1,CA,male,false,40000.0,0.0,0.0], [2,CA,female,false,50000.0,0.0,1.0], [3,UT,female,true,35000.0,2.0,1.0], [4,UT,female,false,20000.0,2.0,1.0], [5,CA,male,true,120000.0,0.0,0.0], [6,TX,male,true,40000.0,1.0,0.0])\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-111726_828439194","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:40-0800","dateFinished":"2018-02-22T08:31:42-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15357"},{"text":"// Putting all featurs together in a vector\n\n// features: state_index, gender_index, income","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-183518_1054552292","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:41-0800","dateFinished":"2018-02-22T08:31:42-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15358"},{"text":"%md \n<b>VectorAssembler</b> is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b>VectorAssembler</b> is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171231-185632_839988333","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:31-0800","dateFinished":"2018-02-22T08:31:31-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15359"},{"text":"import org.apache.spark.ml.feature.VectorAssembler\n\nval featuresAssembler = new VectorAssembler()\n                            .setInputCols(Array(\"income\", \"state_index\", \"gender_index\"))\n                            .setOutputCol(\"features\")","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.feature.VectorAssembler\nfeaturesAssembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_0e6daacf9cda\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-183509_51608077","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:42-0800","dateFinished":"2018-02-22T08:31:43-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15360"},{"text":"val assembled = featuresAssembler.transform(test2)\nassembled.columns\nassembled.head","user":"anonymous","dateUpdated":"2018-02-22T08:31:31-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"assembled: org.apache.spark.sql.DataFrame = [id: string, state: string ... 6 more fields]\nres1271: Array[String] = Array(id, state, gender, owns_car, income, state_index, gender_index, features)\nres1272: org.apache.spark.sql.Row = [1,CA,male,false,40000.0,0.0,0.0,[40000.0,0.0,0.0]]\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20180208-180944_1093055651","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:43-0800","dateFinished":"2018-02-22T08:31:45-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15361"},{"text":"%md\n\n##### No need to normalize features. Some even suggest not doing that.","user":"anonymous","dateUpdated":"2018-02-22T08:31:46-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>No need to normalize features. Some even suggest not doing that.</h5>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20180102-163802_1235362205","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:46-0800","dateFinished":"2018-02-22T08:31:46-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15362"},{"text":"// Define the Random Forest model","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171231-185931_870110302","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:43-0800","dateFinished":"2018-02-22T08:31:45-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15363"},{"text":"import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n\nval rf = new RandomForestClassifier()\n        .setLabelCol(\"owns_car_index\")\n        .setFeaturesCol(\"features\")\n        .setNumTrees(4) // Default is 20\n        .setMaxDepth(3) // Default is 5","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nrf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_14b2daf71c95\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-175748_154615716","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:45-0800","dateFinished":"2018-02-22T08:31:46-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15364"},{"text":"%md\n\n<b>Parameters from TreeClassifierParams:</b>\nsetMaxDepth\nsetMaxBins\nsetMinInstancesPerNode\nsetMinInfoGain\nsetMaxMemoryInMB\nsetCacheNodeIds\nsetCheckpointInterval\nsetImpurity\n\n<b>Parameters from TreeEnsembleParams:</b>\nsetSubsamplingRate\nsetSeed\n\n<b>Parameters from RandomForestParams:</b>\nsetNumTrees\nsetFeatureSubsetStrategy\n\n<b>You can check the definitions and default values in here:</b>\nhttps://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/tree/treeParams.scala","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<b>Parameters from TreeClassifierParams:</b>\n<p>setMaxDepth<br/>setMaxBins<br/>setMinInstancesPerNode<br/>setMinInfoGain<br/>setMaxMemoryInMB<br/>setCacheNodeIds<br/>setCheckpointInterval<br/>setImpurity</p>\n<b>Parameters from TreeEnsembleParams:</b>\n<p>setSubsamplingRate<br/>setSeed</p>\n<b>Parameters from RandomForestParams:</b>\n<p>setNumTrees<br/>setFeatureSubsetStrategy</p>\n<b>You can check the definitions and default values in here:</b>\n<p><a href=\"https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/tree/treeParams.scala\">https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/tree/treeParams.scala</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20180208-191545_914398314","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:32-0800","dateFinished":"2018-02-22T08:31:32-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15365"},{"text":"// Now we put the pipeline together","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184055_1005228155","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:46-0800","dateFinished":"2018-02-22T08:31:46-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15366"},{"text":"import org.apache.spark.ml.{Pipeline, PipelineModel}\n\nval pipeline = new Pipeline().setStages(Array(genderIndexer, stateIndexer) ++ Array(featuresAssembler, labelIndexer, rf))","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.{Pipeline, PipelineModel}\npipeline: org.apache.spark.ml.Pipeline = pipeline_a2389cc6c2d5\n"}]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184111_1069347197","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:46-0800","dateFinished":"2018-02-22T08:31:47-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15367"},{"text":"// We do train-test split first.\nval Array(trainDF, testDF) = dataDF.randomSplit(Array(0.65, 0.35))\n\ntrainDF.count\ntestDF.count","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"trainDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, state: string ... 3 more fields]\ntestDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, state: string ... 3 more fields]\nres1281: Long = 8\nres1282: Long = 5\n"}]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-175830_1631035603","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:47-0800","dateFinished":"2018-02-22T08:31:49-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15368"},{"text":"val model = pipeline.fit(trainDF)","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"model: org.apache.spark.ml.PipelineModel = pipeline_a2389cc6c2d5\n"}]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184311_1955575852","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:48-0800","dateFinished":"2018-02-22T08:31:50-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15369"},{"text":"// We can now make predictions using 'model'","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184309_1609812260","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:50-0800","dateFinished":"2018-02-22T08:31:50-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15370"},{"text":"val testPreds = model.transform(testDF)\ntestPreds.columns\ntestPreds.select(\"owns_car_index\", \"rawPrediction\", \"probability\", \"prediction\").take(3)","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"testPreds: org.apache.spark.sql.DataFrame = [id: string, state: string ... 10 more fields]\nres1285: Array[String] = Array(id, state, gender, owns_car, income, gender_index, state_index, features, owns_car_index, rawPrediction, probability, prediction)\nres1286: Array[org.apache.spark.sql.Row] = Array([0.0,[4.0,0.0],[1.0,0.0],0.0], [0.0,[4.0,0.0],[1.0,0.0],0.0], [1.0,[1.6666666666666665,2.333333333333333],[0.4166666666666667,0.5833333333333334],1.0])\n"}]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-190408_216351950","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:50-0800","dateFinished":"2018-02-22T08:31:52-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15371"},{"text":"labelIndexer.labels\n// so true mapped to index 0.0\n// false mapped to index 1.0","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1287: Array[String] = Array(true, false)\n"}]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171231-190737_1988968839","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:51-0800","dateFinished":"2018-02-22T08:31:53-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15372"},{"text":"// Could compute AUCROC similar to logistic regression since we have two classes here. (see Tutorial 1)","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20180208-190808_498663739","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:52-0800","dateFinished":"2018-02-22T08:31:54-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15373"},{"text":"import org.apache.spark.ml.evaluation.{MulticlassClassificationEvaluator}\n\nval evaluator = new MulticlassClassificationEvaluator()\n        .setLabelCol(\"owns_car_index\")\n        .setPredictionCol(\"prediction\")\n        .setMetricName(\"accuracy\") // metrics:\"f1\" (default), \"weightedPrecision\", \"weightedRecall\", \"accuracy\"","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nevaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_e9a43025063e\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-190636_507344564","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:53-0800","dateFinished":"2018-02-22T08:31:55-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15374"},{"text":"evaluator.evaluate(testPreds)","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1294: Double = 1.0\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-190405_1815223795","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:54-0800","dateFinished":"2018-02-22T08:31:55-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15375"},{"text":"val trainPreds = model.transform(trainDF)\ntrainPreds.head\nevaluator.evaluate(trainPreds)","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"trainPreds: org.apache.spark.sql.DataFrame = [id: string, state: string ... 10 more fields]\nres1295: org.apache.spark.sql.Row = [1,CA,male,false,40000.0,0.0,0.0,[40000.0,0.0,0.0],1.0,[0.3333333333333333,3.6666666666666665],[0.08333333333333333,0.9166666666666666],1.0]\nres1296: Double = 0.75\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-175802_1167304119","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:55-0800","dateFinished":"2018-02-22T08:31:57-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15376"},{"text":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.ml.Model\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.feature.{StringIndexer, VectorAssembler};\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n\n\nval IndexerPostfix = \"_index\"\nval FeaturesVectorColumn = \"features\"\nval ActionForInvalidFlag = \"skip\" // Can also be \"keep\" or \"error\"\nval TrainTestSplitRatio = 0.65\n\ndef trainRFModel(\n    allData: DataFrame,\n    labelCol: String, \n    continuousFeatures: Array[String], \n    categoricalFeatures: Array[String]): Model[_] = {\n    \n    val labelIndexer = new StringIndexer()\n        .setInputCol(labelCol)\n        .setOutputCol(labelCol + IndexerPostfix)\n        .fit(allData)\n        \n    // Indexing categorical features\n    val indexer = (featureName: String) => Seq(\n        new StringIndexer()\n            .setInputCol(featureName)\n            .setOutputCol(featureName + IndexerPostfix)\n            .setHandleInvalid(ActionForInvalidFlag)\n            .fit(allData))\n            \n    val categoricalStages = categoricalFeatures.flatMap(indexer)\n\n    val featuresNames = continuousFeatures ++ categoricalFeatures.map(_ + IndexerPostfix)\n    \n    val featuresAssembler = new VectorAssembler()\n        .setInputCols(featuresNames.toArray)\n        .setOutputCol(FeaturesVectorColumn)\n        \n    val rf = new RandomForestClassifier()\n        .setLabelCol(labelCol + IndexerPostfix)\n        .setFeaturesCol(FeaturesVectorColumn)\n        .setNumTrees(4)\n        .setMaxDepth(3)\n    \n    val pipeline = new Pipeline().setStages(categoricalStages ++ Array(featuresAssembler, labelIndexer, rf))\n    \n    val Array(trainDF, testDF) = allData.randomSplit(Array(TrainTestSplitRatio, 1 - TrainTestSplitRatio))\n    \n    val trainedModel = pipeline.fit(trainDF)\n    \n    // do other things like evaluation..\n    \n    trainedModel\n}","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.ml.Model\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.feature.{StringIndexer, VectorAssembler}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nIndexerPostfix: String = _index\nFeaturesVectorColumn: String = features\nActionForInvalidFlag: String = skip\nTrainTestSplitRatio: Double = 0.65\ntrainRFModel: (allData: org.apache.spark.sql.DataFrame, labelCol: String, continuousFeatures: Array[String], categoricalFeatures: Array[String])org.apache.spark.ml.Model[_]\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-225822_1461200091","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:56-0800","dateFinished":"2018-02-22T08:32:01-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15377"},{"text":"dataDF.columns\nval trainedRFModel = trainRFModel(dataDF, \"owns_car\", Array(\"income\"), Array(\"state\", \"gender\"))","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1300: Array[String] = Array(id, state, gender, owns_car, income)\ntrainedRFModel: org.apache.spark.ml.Model[_] = pipeline_78f759de3e5b\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171231-164523_1371814990","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:31:57-0800","dateFinished":"2018-02-22T08:32:02-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15378"},{"text":"val preds = trainedRFModel.transform(dataDF)\npreds.columns\npreds.head","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"preds: org.apache.spark.sql.DataFrame = [id: string, state: string ... 10 more fields]\nres1301: Array[String] = Array(id, state, gender, owns_car, income, state_index, gender_index, features, owns_car_index, rawPrediction, probability, prediction)\nres1302: org.apache.spark.sql.Row = [1,CA,male,false,40000.0,0.0,0.0,[40000.0,0.0,0.0],1.0,[4.0,0.0],[1.0,0.0],0.0]\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171231-164403_36436813","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:32:01-0800","dateFinished":"2018-02-22T08:32:04-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15379"},{"text":"// Next: We will show how to train a GBT model","user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20180102-163233_332843978","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-22T08:32:03-0800","dateFinished":"2018-02-22T08:32:04-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15380"},{"user":"anonymous","dateUpdated":"2018-02-22T08:31:32-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422729_-869529346","id":"20171231-165520_94273683","dateCreated":"2018-02-08T19:37:02-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15381"}],"name":"DSbyHadi/Classification/RandomForest","id":"2D5PJVTFJ","angularObjects":{"2D23U6FRF:shared_process":[],"2CZ75NCX5:shared_process":[],"2CZR16154:shared_process":[],"2CZ8HPTXX:shared_process":[],"2D16FXM6F:shared_process":[],"2D3BXVJAG:shared_process":[],"2D3TV7XZY:shared_process":[],"2D2CQ39MH:shared_process":[],"2D1QFDUCP:shared_process":[],"2D2HQ94EB:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}