{"paragraphs":[{"text":"%md \n\n### Random Forest Classification in Scala using Spark ML \n\n*Hadi*","user":"anonymous","dateUpdated":"2018-02-16T15:44:02-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Random Forest Classification in Scala using Spark ML</h3>\n<p><em>Hadi</em></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171225-164722_1822736710","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:02-0800","dateFinished":"2018-02-16T15:44:02-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:470"},{"text":"%md\n\n#### Recap:\n<b> Spark ML</b>: Works with DataFrames (vs. Spark Mllib works with RDDs)\n\n<b>DataFrame</b>: This ML API uses DataFrame from Spark SQL as an ML dataset, which can hold a variety of data types. E.g., a DataFrame could have different columns storing text, feature vectors, true labels, and predictions.\n\n<b>Transformer</b>: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions.\n\n<b>Estimator</b>: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.\n\n<b>Pipeline</b>: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.\n\n(from spark.apache.org)","user":"anonymous","dateUpdated":"2018-02-16T16:36:04-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Recap:</h4>\n<p><b> Spark ML</b>: Works with DataFrames (vs. Spark Mllib works with RDDs)</p>\n<p><b>DataFrame</b>: This ML API uses DataFrame from Spark SQL as an ML dataset, which can hold a variety of data types. E.g., a DataFrame could have different columns storing text, feature vectors, true labels, and predictions.</p>\n<p><b>Transformer</b>: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions.</p>\n<p><b>Estimator</b>: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.</p>\n<p><b>Pipeline</b>: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.</p>\n<p>(from spark.apache.org)</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171231-173028_1024443740","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T16:36:04-0800","dateFinished":"2018-02-16T16:36:05-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:471"},{"text":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types._\n\nval schemaStruct =\n        StructType(\n            StructField(\"state\", StringType, false) ::\n            StructField(\"gender\", StringType, false) ::\n            StructField(\"income\", DoubleType, false) :: \n            StructField(\"owns_car\", BooleanType, true) :: Nil)\n\nval data = spark\n            .read\n            .schema(schemaStruct)\n            .option(\"header\", \"true\")\n            .csv(\"/Users/hadi.minooei/Documents/DSbyHadi/car_ownership.csv\")","user":"anonymous","dateUpdated":"2018-02-21T16:37:59-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types._\nschemaStruct: org.apache.spark.sql.types.StructType = StructType(StructField(state,StringType,false), StructField(gender,StringType,false), StructField(income,DoubleType,false), StructField(owns_car,BooleanType,true))\ndata: org.apache.spark.sql.DataFrame = [state: string, gender: string ... 2 more fields]\n"}]},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171225-162607_709880967","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:37:59-0800","dateFinished":"2018-02-21T16:38:01-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:472"},{"text":"data.count\ndata.columns\ndata.printSchema","user":"anonymous","dateUpdated":"2018-02-21T16:38:04-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1187: Long = 13\nres1188: Array[String] = Array(state, gender, income, owns_car)\nroot\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- income: double (nullable = true)\n |-- owns_car: boolean (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171230-112014_1719391521","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:38:04-0800","dateFinished":"2018-02-21T16:38:05-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:473"},{"text":"// We need to predict owns_car --> response\n// Three features to be used: state, gender and income\n// 'income' is a continuous feature \n// 'state' and 'gender' are categorical features","user":"anonymous","dateUpdated":"2018-02-16T15:44:03-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171225-164405_808048175","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:04-0800","dateFinished":"2018-02-16T15:44:04-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:474"},{"text":"// We need to index the owns_car i.e. true -> 0.0 and false -> 1.0 or vice versa.\n// For this we use StringIndexer.","user":"anonymous","dateUpdated":"2018-02-16T15:44:03-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171225-164950_1144267600","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:04-0800","dateFinished":"2018-02-16T15:44:04-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:475"},{"text":"import org.apache.spark.ml.feature.{StringIndexer}\n\nval labelIndexer = new StringIndexer()\n        .setInputCol(\"owns_car\")\n        .setOutputCol(\"owns_car_index\")\n        .fit(dataDF)","user":"anonymous","dateUpdated":"2018-02-21T16:38:58-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.feature.StringIndexer\nlabelIndexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_1501e3524b41\n"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-111645_1636461841","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:38:58-0800","dateFinished":"2018-02-21T16:38:59-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:476"},{"text":"labelIndexer.transform(dataDF).columns\nlabelIndexer.transform(dataDF).take(4)","user":"anonymous","dateUpdated":"2018-02-21T16:39:02-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1191: Array[String] = Array(id, state, gender, owns_car, income, owns_car_index)\nres1192: Array[org.apache.spark.sql.Row] = Array([1,CA,male,false,40000.0,1.0], [2,CA,female,false,50000.0,1.0], [3,UT,female,true,35000.0,0.0], [4,UT,female,false,20000.0,1.0])\n"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-182705_1615244198","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:39:02-0800","dateFinished":"2018-02-21T16:39:03-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:477"},{"text":"// 'income' is a continuous feature \n\n// 'state' and 'gender' are categorical features, so need to be indexed.","user":"anonymous","dateUpdated":"2018-02-16T15:44:03-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171231-184422_1966221586","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:05-0800","dateFinished":"2018-02-16T15:44:05-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:478"},{"text":"%md\n##### No need to do OneHotEncoding","user":"anonymous","dateUpdated":"2018-02-16T15:44:03-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>No need to do OneHotEncoding</h5>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20180208-193038_2116727936","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:03-0800","dateFinished":"2018-02-16T15:44:03-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:479"},{"text":"import org.apache.spark.ml.feature.OneHotEncoder;\n\nval genderIndexer = new StringIndexer()\n        .setInputCol(\"gender\")\n        .setOutputCol(\"gender\" + \"_index\")\n        .setHandleInvalid(\"skip\")\n        .fit(dataDF)","user":"anonymous","dateUpdated":"2018-02-21T16:40:23-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.feature.OneHotEncoder\ngenderIndexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_692a6b45fae1\n"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-111727_1248125003","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:40:24-0800","dateFinished":"2018-02-21T16:40:24-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:480"},{"text":"val stateIndexer = new StringIndexer()\n        .setInputCol(\"state\")\n        .setOutputCol(\"state\" + \"_index\")\n        .setHandleInvalid(\"skip\")\n        .fit(dataDF)","user":"anonymous","dateUpdated":"2018-02-21T16:40:26-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"stateIndexer: org.apache.spark.ml.feature.StringIndexerModel = strIdx_2d72d2cffc74\n"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-111727_1105500600","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:40:26-0800","dateFinished":"2018-02-21T16:40:27-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:481"},{"text":"val test1 = stateIndexer.transform(dataDF)\nval test2 = genderIndexer.transform(test1)","user":"anonymous","dateUpdated":"2018-02-21T16:40:34-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"test1: org.apache.spark.sql.DataFrame = [id: string, state: string ... 4 more fields]\ntest2: org.apache.spark.sql.DataFrame = [id: string, state: string ... 5 more fields]\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-111726_1473112042","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:40:34-0800","dateFinished":"2018-02-21T16:40:35-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:482"},{"text":"test2.columns\ntest2.take(6)","user":"anonymous","dateUpdated":"2018-02-21T16:40:38-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1194: Array[String] = Array(id, state, gender, owns_car, income, state_index, gender_index)\nres1195: Array[org.apache.spark.sql.Row] = Array([1,CA,male,false,40000.0,0.0,0.0], [2,CA,female,false,50000.0,0.0,1.0], [3,UT,female,true,35000.0,2.0,1.0], [4,UT,female,false,20000.0,2.0,1.0], [5,CA,male,true,120000.0,0.0,0.0], [6,TX,male,true,40000.0,1.0,0.0])\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-111726_828439194","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:40:38-0800","dateFinished":"2018-02-21T16:40:39-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:483"},{"text":"// Putting all featurs together in a vector\n\n// features: state_index, gender_index, income","user":"anonymous","dateUpdated":"2018-02-16T15:44:03-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-183518_1054552292","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:06-0800","dateFinished":"2018-02-16T15:44:07-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:484"},{"text":"%md \n<b>VectorAssembler</b> is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector","user":"anonymous","dateUpdated":"2018-02-16T15:44:03-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b>VectorAssembler</b> is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171231-185632_839988333","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:03-0800","dateFinished":"2018-02-16T15:44:03-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:485"},{"text":"import org.apache.spark.ml.feature.VectorAssembler\n\nval featuresAssembler = new VectorAssembler()\n                            .setInputCols(Array(\"income\", \"state_index\", \"gender_index\"))\n                            .setOutputCol(\"features\")","user":"anonymous","dateUpdated":"2018-02-21T16:41:12-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.feature.VectorAssembler\nfeaturesAssembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_4cefd225f86f\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-183509_51608077","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:41:12-0800","dateFinished":"2018-02-21T16:41:13-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:486"},{"text":"val assembled = featuresAssembler.transform(test2)\nassembled.columns\nassembled.head","user":"anonymous","dateUpdated":"2018-02-21T16:41:15-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"assembled: org.apache.spark.sql.DataFrame = [id: string, state: string ... 6 more fields]\nres1197: Array[String] = Array(id, state, gender, owns_car, income, state_index, gender_index, features)\nres1198: org.apache.spark.sql.Row = [1,CA,male,false,40000.0,0.0,0.0,[40000.0,0.0,0.0]]\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20180208-180944_1093055651","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:41:15-0800","dateFinished":"2018-02-21T16:41:17-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:487"},{"text":"%md\n\n##### No need to normalize features. Some even suggest not doing that.","user":"anonymous","dateUpdated":"2018-02-16T15:44:03-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>No need to normalize features. Some even suggest not doing that.</h5>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20180102-163802_1235362205","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:03-0800","dateFinished":"2018-02-16T15:44:03-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:488"},{"text":"// Define the Random Forest model","user":"anonymous","dateUpdated":"2018-02-16T15:44:03-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171231-185931_870110302","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:07-0800","dateFinished":"2018-02-16T15:44:07-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:489"},{"text":"import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n\nval rf = new RandomForestClassifier()\n        .setLabelCol(\"owns_car_index\")\n        .setFeaturesCol(\"features\")\n        .setNumTrees(4) // Default is 20\n        .setMaxDepth(3) // Default is 5","user":"anonymous","dateUpdated":"2018-02-21T16:42:48-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nrf: org.apache.spark.ml.classification.RandomForestClassifier = rfc_f56ffb62d2fb\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-175748_154615716","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:42:48-0800","dateFinished":"2018-02-21T16:42:48-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:490"},{"text":"%md\n\n<b>Parameters from TreeClassifierParams:</b>\nsetMaxDepth\nsetMaxBins\nsetMinInstancesPerNode\nsetMinInfoGain\nsetMaxMemoryInMB\nsetCacheNodeIds\nsetCheckpointInterval\nsetImpurity\n\n<b>Parameters from TreeEnsembleParams:</b>\nsetSubsamplingRate\nsetSeed\n\n<b>Parameters from RandomForestParams:</b>\nsetNumTrees\nsetFeatureSubsetStrategy\n\n<b>You can check the definitions and default values in here:</b>\nhttps://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/tree/treeParams.scala","user":"anonymous","dateUpdated":"2018-02-21T11:56:01-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<b>Parameters from TreeClassifierParams:</b>\n<p>setMaxDepth<br/>setMaxBins<br/>setMinInstancesPerNode<br/>setMinInfoGain<br/>setMaxMemoryInMB<br/>setCacheNodeIds<br/>setCheckpointInterval<br/>setImpurity</p>\n<b>Parameters from TreeEnsembleParams:</b>\n<p>setSubsamplingRate<br/>setSeed</p>\n<b>Parameters from RandomForestParams:</b>\n<p>setNumTrees<br/>setFeatureSubsetStrategy</p>\n<b>You can check the definitions and default values in here:</b>\n<p><a href=\"https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/tree/treeParams.scala\">https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/tree/treeParams.scala</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20180208-191545_914398314","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T11:56:01-0800","dateFinished":"2018-02-21T11:56:01-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:491"},{"text":"// Now we put the pipeline together","user":"anonymous","dateUpdated":"2018-02-16T15:44:04-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184055_1005228155","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:08-0800","dateFinished":"2018-02-16T15:44:08-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:492"},{"text":"import org.apache.spark.ml.{Pipeline, PipelineModel}\n\nval pipeline = new Pipeline().setStages(Array(genderIndexer, stateIndexer) ++ Array(featuresAssembler, labelIndexer, rf))","user":"anonymous","dateUpdated":"2018-02-21T16:44:10-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.{Pipeline, PipelineModel}\npipeline: org.apache.spark.ml.Pipeline = pipeline_611784ff5109\n"}]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184111_1069347197","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:44:10-0800","dateFinished":"2018-02-21T16:44:11-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:493"},{"text":"// We do train-test split first.\nval Array(trainDF, testDF) = dataDF.randomSplit(Array(0.65, 0.35))\n\ntrainDF.count\ntestDF.count","user":"anonymous","dateUpdated":"2018-02-21T16:47:04-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"trainDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, state: string ... 3 more fields]\ntestDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, state: string ... 3 more fields]\nres1217: Long = 10\nres1218: Long = 3\n"}]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-175830_1631035603","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:47:04-0800","dateFinished":"2018-02-21T16:47:05-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:494"},{"text":"val model = pipeline.fit(trainDF)","user":"anonymous","dateUpdated":"2018-02-21T16:47:10-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"model: org.apache.spark.ml.PipelineModel = pipeline_611784ff5109\n"}]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184311_1955575852","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:47:10-0800","dateFinished":"2018-02-21T16:47:11-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:495"},{"text":"// We can now make predictions using 'model'","user":"anonymous","dateUpdated":"2018-02-16T15:44:04-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184309_1609812260","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:09-0800","dateFinished":"2018-02-16T15:44:09-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:496"},{"text":"val testPreds = model.transform(testDF)\ntestPreds.columns\ntestPreds.select(\"owns_car_index\", \"rawPrediction\", \"probability\", \"prediction\").take(3)","user":"anonymous","dateUpdated":"2018-02-21T16:47:13-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"testPreds: org.apache.spark.sql.DataFrame = [id: string, state: string ... 10 more fields]\nres1219: Array[String] = Array(id, state, gender, owns_car, income, gender_index, state_index, features, owns_car_index, rawPrediction, probability, prediction)\nres1220: Array[org.apache.spark.sql.Row] = Array([1.0,[4.0,0.0],[1.0,0.0],0.0], [1.0,[4.0,0.0],[1.0,0.0],0.0], [1.0,[4.0,0.0],[1.0,0.0],0.0])\n"}]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-190408_216351950","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:47:13-0800","dateFinished":"2018-02-21T16:47:15-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:497"},{"text":"labelIndexer.labels\n// so true mapped to index 0.0\n// false mapped to index 1.0","user":"anonymous","dateUpdated":"2018-02-21T16:47:38-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1221: Array[String] = Array(true, false)\n"}]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171231-190737_1988968839","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:47:38-0800","dateFinished":"2018-02-21T16:47:38-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:498"},{"text":"// Could compute AUCROC similar to logistic regression since we have two classes here. (see Tutorial 1)","user":"anonymous","dateUpdated":"2018-02-16T15:44:04-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20180208-190808_498663739","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:10-0800","dateFinished":"2018-02-16T15:44:10-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:499"},{"text":"import org.apache.spark.ml.evaluation.{MulticlassClassificationEvaluator}\n\nval evaluator = new MulticlassClassificationEvaluator()\n        .setLabelCol(\"owns_car_index\")\n        .setPredictionCol(\"prediction\")\n        .setMetricName(\"accuracy\") // metrics:\"f1\" (default), \"weightedPrecision\", \"weightedRecall\", \"accuracy\"","user":"anonymous","dateUpdated":"2018-02-21T16:49:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\nevaluator: org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator = mcEval_ccf90c9b11ac\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-190636_507344564","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:49:08-0800","dateFinished":"2018-02-21T16:49:09-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:500"},{"text":"evaluator.evaluate(testPreds)","user":"anonymous","dateUpdated":"2018-02-21T16:49:12-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1226: Double = 0.0\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-190405_1815223795","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:49:12-0800","dateFinished":"2018-02-21T16:49:13-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:501"},{"text":"val trainPreds = model.transform(trainDF)\ntrainPreds.head\nevaluator.evaluate(trainPreds)","user":"anonymous","dateUpdated":"2018-02-21T16:49:22-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"trainPreds: org.apache.spark.sql.DataFrame = [id: string, state: string ... 10 more fields]\nres1227: org.apache.spark.sql.Row = [1,CA,male,false,40000.0,0.0,0.0,[40000.0,0.0,0.0],1.0,[1.0,3.0],[0.25,0.75],1.0]\nres1228: Double = 0.9\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-175802_1167304119","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:49:22-0800","dateFinished":"2018-02-21T16:49:23-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:502"},{"text":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.ml.Model\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.feature.{StringIndexer, VectorAssembler};\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n\n\nval IndexerPostfix = \"_index\"\nval FeaturesVectorColumn = \"features\"\nval ActionForInvalidFlag = \"skip\" // Can also be \"keep\" or \"error\"\nval TrainTestSplitRatio = 0.65\n\ndef trainRFModel(\n    allData: DataFrame,\n    labelCol: String, \n    continuousFeatures: Array[String], \n    categoricalFeatures: Array[String]): Model[_] = {\n    \n    val labelIndexer = new StringIndexer()\n        .setInputCol(labelCol)\n        .setOutputCol(labelCol + IndexerPostfix)\n        .fit(allData)\n        \n    // Indexing categorical features\n    val indexer = (featureName: String) => Seq(\n        new StringIndexer()\n            .setInputCol(featureName)\n            .setOutputCol(featureName + IndexerPostfix)\n            .setHandleInvalid(ActionForInvalidFlag)\n            .fit(allData))\n            \n    val categoricalStages = categoricalFeatures.flatMap(indexer)\n\n    val featuresNames = continuousFeatures ++ categoricalFeatures.map(_ + IndexerPostfix)\n    \n    val featuresAssembler = new VectorAssembler()\n        .setInputCols(featuresNames.toArray)\n        .setOutputCol(FeaturesVectorColumn)\n        \n    val rf = new RandomForestClassifier()\n        .setLabelCol(labelCol + IndexerPostfix)\n        .setFeaturesCol(FeaturesVectorColumn)\n        .setNumTrees(4)\n        .setMaxDepth(3)\n    \n    val pipeline = new Pipeline().setStages(categoricalStages ++ Array(featuresAssembler, labelIndexer, rf))\n    \n    val Array(trainDF, testDF) = allData.randomSplit(Array(TrainTestSplitRatio, 1 - TrainTestSplitRatio))\n    \n    val trainedModel = pipeline.fit(trainDF)\n    \n    // do other things like evaluation..\n    \n    trainedModel\n}","user":"anonymous","dateUpdated":"2018-02-21T16:51:11-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.ml.Model\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.feature.{StringIndexer, VectorAssembler}\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\nIndexerPostfix: String = _index\nFeaturesVectorColumn: String = features\nActionForInvalidFlag: String = skip\nTrainTestSplitRatio: Double = 0.65\ntrainRFModel: (allData: org.apache.spark.sql.DataFrame, labelCol: String, continuousFeatures: Array[String], categoricalFeatures: Array[String])org.apache.spark.ml.Model[_]\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-225822_1461200091","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:51:11-0800","dateFinished":"2018-02-21T16:51:15-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:503"},{"text":"dataDF.columns\nval trainedRFModel = trainRFModel(dataDF, \"owns_car\", Array(\"income\"), Array(\"state\", \"gender\"))","user":"anonymous","dateUpdated":"2018-02-21T16:51:22-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"res1232: Array[String] = Array(id, state, gender, owns_car, income)\ntrainedRFModel: org.apache.spark.ml.Model[_] = pipeline_87e211985efa\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171231-164523_1371814990","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T16:51:22-0800","dateFinished":"2018-02-21T16:51:23-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:504"},{"text":"val preds = trainedRFModel.transform(dataDF)\npreds.columns\npreds.head","user":"anonymous","dateUpdated":"2018-02-21T18:18:51-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"preds: org.apache.spark.sql.DataFrame = [id: string, state: string ... 10 more fields]\nres1241: Array[String] = Array(id, state, gender, owns_car, income, state_index, gender_index, features, owns_car_index, rawPrediction, probability, prediction)\nres1242: org.apache.spark.sql.Row = [1,CA,male,false,40000.0,0.0,0.0,[40000.0,0.0,0.0],1.0,[1.35,2.65],[0.3375,0.6625],1.0]\n"}]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171231-164403_36436813","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-21T18:18:51-0800","dateFinished":"2018-02-21T18:18:53-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:505"},{"text":"// Next: We will show how to train a GBT model","user":"anonymous","dateUpdated":"2018-02-21T16:53:06-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20180102-163233_332843978","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-16T15:44:15-0800","dateFinished":"2018-02-16T15:44:15-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:506"},{"dateUpdated":"2018-02-08T19:37:02-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422729_-869529346","id":"20171231-165520_94273683","dateCreated":"2018-02-08T19:37:02-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:507"}],"name":"DSbyHadi/Classification/RandomForest","id":"2D5PJVTFJ","angularObjects":{"2D23U6FRF:shared_process":[],"2CZ75NCX5:shared_process":[],"2CZR16154:shared_process":[],"2CZ8HPTXX:shared_process":[],"2D16FXM6F:shared_process":[],"2D3BXVJAG:shared_process":[],"2D3TV7XZY:shared_process":[],"2D2CQ39MH:shared_process":[],"2D1QFDUCP:shared_process":[],"2D2HQ94EB:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}