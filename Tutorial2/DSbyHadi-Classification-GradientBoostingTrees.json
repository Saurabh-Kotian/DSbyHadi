{"paragraphs":[{"text":"%md \n\n### Random Forest Classification in Scala using Spark ML \n\n*Hadi*","user":"anonymous","dateUpdated":"2018-02-25T12:05:02-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3><b> Spark ML</b> Forest Classification in Scala using Spark ML</h3>\n<p><em>Hadi</em></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171225-164722_1822736710","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:02-0800","dateFinished":"2018-02-25T12:05:05-0800","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:366"},{"text":"%md\n\n#### Recap:\n<b> Spark ML</b>: Works with DataFrames (vs. Spark Mllib works with RDDs)\n\n<b>DataFrame</b>: This ML API uses DataFrame from Spark SQL as an ML dataset, which can hold a variety of data types. E.g., a DataFrame could have different columns storing text, feature vectors, true labels, and predictions.\n\n<b>Transformer</b>: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions.\n\n<b>Estimator</b>: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.\n\n<b>Pipeline</b>: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.\n\n(from spark.apache.org)","user":"anonymous","dateUpdated":"2018-02-25T12:05:10-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Recap:</h4>\n<p><b> Spark ML</b>: Works with DataFrames (vs. Spark Mllib works with RDDs)</p>\n<p><b>DataFrame</b>: This ML API uses DataFrame from Spark SQL as an ML dataset, which can hold a variety of data types. E.g., a DataFrame could have different columns storing text, feature vectors, true labels, and predictions.</p>\n<p><b>Transformer</b>: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions.</p>\n<p><b>Estimator</b>: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.</p>\n<p><b>Pipeline</b>: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.</p>\n<p>(from spark.apache.org)</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171231-173028_1024443740","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:10-0800","dateFinished":"2018-02-25T12:05:10-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:367"},{"text":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.sql.types._\n\nval schemaStruct =\n        StructType(\n            StructField(\"id\", IntegerType, false) ::\n            StructField(\"income\", DoubleType, false) ::\n            StructField(\"state\", StringType, false) ::\n            StructField(\"gender\", StringType, false) ::\n            StructField(\"owns_car\", StringType, true) :: Nil)\n\nval dataDF = spark\n                .read\n                .schema(schemaStruct)\n                .option(\"header\", \"true\")\n                .csv(\"/Users/hadi.minooei/Documents/DSbyHadi/car_ownership.csv\")","user":"anonymous","dateUpdated":"2018-02-25T12:05:03-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171225-162607_709880967","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:04-0800","dateFinished":"2018-02-25T12:05:15-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:368","errorMessage":""},{"text":"dataDF.count\ndataDF.columns\ndataDF.printSchema","user":"anonymous","dateUpdated":"2018-02-25T12:05:04-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422724_-867605602","id":"20171230-112014_1719391521","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:05-0800","dateFinished":"2018-02-25T12:05:18-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:369","errorMessage":""},{"text":"// We need to predict owns_car --> response\n// Three features to be used: state, gender and income\n// 'income' is a continuous feature \n// 'state' and 'gender' are categorical features","user":"anonymous","dateUpdated":"2018-02-25T12:05:05-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171225-164405_808048175","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:16-0800","dateFinished":"2018-02-25T12:05:20-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:370","errorMessage":""},{"text":"import org.apache.spark.ml.feature.{StringIndexer}\n\nval labelIndexer = new StringIndexer()\n        .setInputCol(\"owns_car\")\n        .setOutputCol(\"owns_car_index\")\n        .fit(dataDF)","user":"anonymous","dateUpdated":"2018-02-25T12:05:05-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-111645_1636461841","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:21-0800","dateFinished":"2018-02-25T12:05:26-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:372","errorMessage":""},{"text":"// We need to index the owns_car i.e. true -> 0.0 and false -> 1.0 or vice versa.\n// For this we use StringIndexer.","user":"anonymous","dateUpdated":"2018-02-25T12:05:05-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171225-164950_1144267600","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:18-0800","dateFinished":"2018-02-25T12:05:23-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:371","errorMessage":"","focus":true},{"text":"// 'income' is a continuous feature \n\n// 'state' and 'gender' are categorical features, so need to be indexed.","user":"anonymous","dateUpdated":"2018-02-25T12:05:06-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171231-184422_1966221586","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:26-0800","dateFinished":"2018-02-25T12:05:31-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:374","errorMessage":"","focus":true},{"text":"labelIndexer.transform(dataDF).columns\nlabelIndexer.transform(dataDF).take(4)","user":"anonymous","dateUpdated":"2018-02-25T12:05:05-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-182705_1615244198","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:23-0800","dateFinished":"2018-02-25T12:05:28-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:373","errorMessage":""},{"text":"%md\n##### No need to do OneHotEncoding","user":"anonymous","dateUpdated":"2018-02-25T12:05:06-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>No need to do OneHotEncoding</h5>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20180208-193038_2116727936","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:06-0800","dateFinished":"2018-02-25T12:05:06-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:375"},{"text":"val genderIndexer = new StringIndexer()\n        .setInputCol(\"gender\")\n        .setOutputCol(\"gender\" + \"_index\")\n        .setHandleInvalid(\"skip\")\n        .fit(dataDF)","user":"anonymous","dateUpdated":"2018-02-25T12:05:06-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-111727_1248125003","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:28-0800","dateFinished":"2018-02-25T12:05:33-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:376","errorMessage":""},{"text":"val stateIndexer = new StringIndexer()\n        .setInputCol(\"state\")\n        .setOutputCol(\"state\" + \"_index\")\n        .setHandleInvalid(\"skip\")\n        .fit(dataDF)","user":"anonymous","dateUpdated":"2018-02-25T12:05:06-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422725_-867990351","id":"20171230-111727_1105500600","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:31-0800","dateFinished":"2018-02-25T12:05:38-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:377","errorMessage":""},{"text":"val test1 = stateIndexer.transform(dataDF)\nval test2 = genderIndexer.transform(test1)","user":"anonymous","dateUpdated":"2018-02-25T12:05:06-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-111726_1473112042","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:35-0800","dateFinished":"2018-02-25T12:06:20-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:378","errorMessage":""},{"text":"test2.columns\ntest2.take(6)","user":"anonymous","dateUpdated":"2018-02-25T12:05:06-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-111726_828439194","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:40-0800","dateFinished":"2018-02-25T12:06:31-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:379","errorMessage":""},{"text":"// Putting all featurs together in a vector\n\n// features: state_index, gender_index, income","user":"anonymous","dateUpdated":"2018-02-25T12:05:06-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-183518_1054552292","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:06:22-0800","dateFinished":"2018-02-25T12:06:35-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:380","errorMessage":""},{"text":"%md \n<b>VectorAssembler</b> is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector","user":"anonymous","dateUpdated":"2018-02-25T12:05:07-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><b>VectorAssembler</b> is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171231-185632_839988333","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:07-0800","dateFinished":"2018-02-25T12:05:07-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:381"},{"text":"import org.apache.spark.ml.feature.VectorAssembler\n\nval featuresAssembler = new VectorAssembler()\n                            .setInputCols(Array(\"income\", \"state_index\", \"gender_index\"))\n                            .setOutputCol(\"features\")","user":"anonymous","dateUpdated":"2018-02-25T12:05:07-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.OutOfMemoryError: GC overhead limit exceeded\n"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-183509_51608077","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:06:31-0800","dateFinished":"2018-02-25T12:06:41-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:382"},{"text":"val assembled = featuresAssembler.transform(test2)\nassembled.columns\nassembled.head","user":"anonymous","dateUpdated":"2018-02-25T12:05:07-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20180208-180944_1093055651","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:06:36-0800","dateFinished":"2018-02-25T12:06:53-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:383","errorMessage":""},{"text":"%md\n\n##### No need to normalize features. Some even suggest not doing that.","user":"anonymous","dateUpdated":"2018-02-25T12:05:07-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h5>No need to normalize features. Some even suggest not doing that.</h5>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20180102-163802_1235362205","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:07-0800","dateFinished":"2018-02-25T12:05:07-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:384"},{"text":"// Define the Random Forest model","user":"anonymous","dateUpdated":"2018-02-25T12:05:07-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171231-185931_870110302","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:06:41-0800","dateFinished":"2018-02-25T12:07:00-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:385","errorMessage":""},{"text":"import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n\nval rf = new RandomForestClassifier()\n        .setLabelCol(\"owns_car_index\")\n        .setFeaturesCol(\"features\")\n        .setNumTrees(4) // Default is 20\n        .setMaxDepth(3) // Default is 5","user":"anonymous","dateUpdated":"2018-02-25T12:05:07-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20171230-175748_154615716","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:06:53-0800","dateFinished":"2018-02-25T12:07:14-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:386","errorMessage":""},{"text":"%md\n\n<b>Parameters from TreeClassifierParams:</b>\nsetMaxDepth\nsetMaxBins\nsetMinInstancesPerNode\nsetMinInfoGain\nsetMaxMemoryInMB\nsetCacheNodeIds\nsetCheckpointInterval\nsetImpurity\n\n<b>Parameters from TreeEnsembleParams:</b>\nsetSubsamplingRate\nsetSeed\n\n<b>Parameters from RandomForestParams:</b>\nsetNumTrees\nsetFeatureSubsetStrategy\n\n<b>You can check the definitions and default values in here:</b>\nhttps://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/tree/treeParams.scala","user":"anonymous","dateUpdated":"2018-02-25T12:05:07-0800","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<b>Parameters from TreeClassifierParams:</b>\n<p>setMaxDepth<br/>setMaxBins<br/>setMinInstancesPerNode<br/>setMinInfoGain<br/>setMaxMemoryInMB<br/>setCacheNodeIds<br/>setCheckpointInterval<br/>setImpurity</p>\n<b>Parameters from TreeEnsembleParams:</b>\n<p>setSubsamplingRate<br/>setSeed</p>\n<b>Parameters from RandomForestParams:</b>\n<p>setNumTrees<br/>setFeatureSubsetStrategy</p>\n<b>You can check the definitions and default values in here:</b>\n<p><a href=\"https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/tree/treeParams.scala\">https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/tree/treeParams.scala</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1518147422726_-866836104","id":"20180208-191545_914398314","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:05:07-0800","dateFinished":"2018-02-25T12:05:07-0800","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:387"},{"text":"// Now we put the pipeline together","user":"anonymous","dateUpdated":"2018-02-25T12:05:07-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184055_1005228155","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:06:55-0800","dateFinished":"2018-02-25T12:07:02-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:388","errorMessage":""},{"text":"import org.apache.spark.ml.{Pipeline, PipelineModel}\n\nval pipeline = new Pipeline().setStages(Array(genderIndexer, stateIndexer) ++ Array(featuresAssembler, labelIndexer, rf))","user":"anonymous","dateUpdated":"2018-02-25T12:05:07-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184111_1069347197","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:02-0800","dateFinished":"2018-02-25T12:07:07-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:389","errorMessage":""},{"text":"// We do train-test split first.\nval Array(trainDF, testDF) = dataDF.randomSplit(Array(0.75, 0.25))\n\ntrainDF.count\ntestDF.count","user":"anonymous","dateUpdated":"2018-02-25T12:05:07-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-175830_1631035603","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:07-0800","dateFinished":"2018-02-25T12:07:18-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:390","errorMessage":""},{"text":"val model = pipeline.fit(trainDF)","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184311_1955575852","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:14-0800","dateFinished":"2018-02-25T12:07:30-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:391","errorMessage":""},{"text":"// We can now make predictions using 'model'","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-184309_1609812260","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:18-0800","dateFinished":"2018-02-25T12:07:32-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:392","errorMessage":""},{"text":"val testPreds = model.transform(testDF)\ntestPreds.columns\ntestPreds.select(\"owns_car_index\", \"rawPrediction\", \"probability\", \"prediction\").take(3)","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171230-190408_216351950","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:32-0800","dateFinished":"2018-02-25T12:07:36-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:393","errorMessage":""},{"text":"labelIndexer.labels\n// so true mapped to index 0.0\n// false mapped to index 1.0","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20171231-190737_1988968839","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:32-0800","dateFinished":"2018-02-25T12:07:37-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:394","errorMessage":""},{"text":"// Could compute AUCROC similar to logistic regression since we have two classes here. (see Tutorial 1)","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422727_-867220853","id":"20180208-190808_498663739","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:35-0800","dateFinished":"2018-02-25T12:07:41-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:395","errorMessage":""},{"text":"import org.apache.spark.ml.evaluation.{MulticlassClassificationEvaluator}\n\nval evaluator = new MulticlassClassificationEvaluator()\n        .setLabelCol(\"owns_car_index\")\n        .setPredictionCol(\"prediction\")\n        .setMetricName(\"accuracy\") // metrics:\"f1\" (default), \"weightedPrecision\", \"weightedRecall\", \"accuracy\"","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-190636_507344564","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:38-0800","dateFinished":"2018-02-25T12:07:43-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:396","errorMessage":""},{"text":"evaluator.evaluate(testPreds)","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-190405_1815223795","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:40-0800","dateFinished":"2018-02-25T12:07:45-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:397","errorMessage":""},{"text":"val trainPreds = model.transform(trainDF)\ntrainPreds.head\nevaluator.evaluate(trainPreds)","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-175802_1167304119","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:43-0800","dateFinished":"2018-02-25T12:07:48-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:398","errorMessage":""},{"text":"import org.apache.spark.sql.DataFrame\nimport org.apache.spark.ml.Model\nimport org.apache.spark.ml.linalg.Vectors\nimport org.apache.spark.ml.feature.{StringIndexer, VectorAssembler};\nimport org.apache.spark.ml.{Pipeline, PipelineModel}\nimport org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}\n\n\nval IndexerPostfix = \"_index\"\nval FeaturesVectorColumn = \"features\"\nval ActionForInvalidFlag = \"skip\" // Can also be \"keep\" or \"error\"\nval TrainTestSplitRatio = 0.65\n\ndef trainRFModel(\n    allData: DataFrame,\n    labelCol: String, \n    continuousFeatures: Array[String], \n    categoricalFeatures: Array[String]): Model[_] = {\n    \n    val labelIndexer = new StringIndexer()\n        .setInputCol(labelCol)\n        .setOutputCol(labelCol + IndexerPostfix)\n        .fit(allData)\n        \n    // Indexing categorical features\n    val indexer = (featureName: String) => Seq(\n        new StringIndexer()\n            .setInputCol(featureName)\n            .setOutputCol(featureName + IndexerPostfix)\n            .setHandleInvalid(ActionForInvalidFlag)\n            .fit(allData))\n            \n    val categoricalStages = categoricalFeatures.flatMap(indexer)\n\n    val featuresNames = continuousFeatures ++ categoricalFeatures.map(_ + IndexerPostfix)\n    \n    val featuresAssembler = new VectorAssembler()\n        .setInputCols(featuresNames.toArray)\n        .setOutputCol(FeaturesVectorColumn)\n        \n    val rf = new RandomForestClassifier()\n        .setLabelCol(labelCol + IndexerPostfix)\n        .setFeaturesCol(FeaturesVectorColumn)\n        .setNumTrees(4)\n        .setMaxDepth(3)\n    \n    val pipeline = new Pipeline().setStages(categoricalStages ++ Array(featuresAssembler, labelIndexer, rf))\n    \n    val Array(trainDF, testDF) = allData.randomSplit(Array(TrainTestSplitRatio, 1 - TrainTestSplitRatio))\n    \n    val trainedModel = pipeline.fit(trainDF)\n    \n    // do other things like evaluation..\n    \n    trainedModel\n}","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171230-225822_1461200091","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:46-0800","dateFinished":"2018-02-25T12:07:51-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:399","errorMessage":""},{"text":"dataDF.columns\nval trainedRFModel = trainRFModel(dataDF, \"owns_car\", Array(\"income\"), Array(\"state\", \"gender\"))","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171231-164523_1371814990","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:49-0800","dateFinished":"2018-02-25T12:07:53-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:400","errorMessage":""},{"text":"val preds = trainedRFModel.transform(dataDF)\npreds.columns\npreds.head","user":"anonymous","dateUpdated":"2018-02-25T12:05:08-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20171231-164403_36436813","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:51-0800","dateFinished":"2018-02-25T12:07:55-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:401","errorMessage":""},{"text":"// Next: We will show how to train a GBT model","user":"anonymous","dateUpdated":"2018-02-25T12:05:09-0800","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422728_-869144597","id":"20180102-163233_332843978","dateCreated":"2018-02-08T19:37:02-0800","dateStarted":"2018-02-25T12:07:55-0800","dateFinished":"2018-02-25T12:07:59-0800","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:402","errorMessage":""},{"user":"anonymous","dateUpdated":"2018-02-24T12:22:17-0800","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1518147422729_-869529346","id":"20171231-165520_94273683","dateCreated":"2018-02-08T19:37:02-0800","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:403"}],"name":"DSbyHadi/Classification/RandomForest","id":"2D5PJVTFJ","angularObjects":{"2D23U6FRF:shared_process":[],"2CZ75NCX5:shared_process":[],"2CZR16154:shared_process":[],"2CZ8HPTXX:shared_process":[],"2D16FXM6F:shared_process":[],"2D3BXVJAG:shared_process":[],"2D3TV7XZY:shared_process":[],"2D2CQ39MH:shared_process":[],"2D1QFDUCP:shared_process":[],"2D2HQ94EB:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}